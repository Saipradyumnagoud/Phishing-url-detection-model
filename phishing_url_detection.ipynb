{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from scipy.sparse import hstack\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import sys\n",
    "from scipy.sparse import csr_matrix # Added for explicit sparse matrix handling\n",
    "\n",
    "# Set a style for plots\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f627fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 1Ô∏è‚É£ Load Datasets\n",
    "# =======================\n",
    "try:\n",
    "    # ONLY loading the malicious_phish.csv as requested\n",
    "    phish_urls = pd.read_csv(\"./Datasets/malicious_phish.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: 'malicious_phish.csv' not found. Please ensure it's in the 'Datasets' directory.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"‚úÖ Dataset Loaded Successfully!\")\n",
    "print(f\"malicious_phish.csv ‚Üí {phish_urls.shape}\")\n",
    "\n",
    "# Filter out 'defacement', 'malware', etc., if you want a binary (Phishing/Benign) classification\n",
    "phish_urls['type'] = phish_urls['type'].astype('category').cat.remove_unused_categories()\n",
    "phish_urls = phish_urls[phish_urls['type'].isin(['benign', 'phishing'])].copy()\n",
    "\n",
    "# =======================\n",
    "# 2Ô∏è‚É£ Feature Extraction Function\n",
    "# =======================\n",
    "def extract_features(url):\n",
    "    \"\"\"Extracts a consistent set of handcrafted features from a URL.\"\"\"\n",
    "    url = str(url).strip()\n",
    "    if not url:\n",
    "        url = \"http://invalid-url\"\n",
    "    if \"://\" not in url:\n",
    "        url = \"http://\" + url\n",
    "    try:\n",
    "        parsed = urlparse(url)\n",
    "    except Exception:\n",
    "        parsed = urlparse(\"http://invalid-url\")\n",
    "\n",
    "    features = {}\n",
    "    features['url_length'] = len(url)\n",
    "    features['num_dots'] = url.count('.')\n",
    "    features['num_hyphens'] = url.count('-')\n",
    "    features['num_digits'] = sum(c.isdigit() for c in url)\n",
    "    features['num_params'] = url.count('=') + url.count('?') + url.count('&')\n",
    "    features['has_https'] = 1 if url.startswith('https') else 0\n",
    "    features['has_ip'] = 1 if re.match(r'^(?:http[s]?://)?\\d{1,3}(?:\\.\\d{1,3}){3}', url) else 0\n",
    "    features['num_subdirs'] = url.count('/')\n",
    "    features['has_at_symbol'] = 1 if '@' in url else 0\n",
    "    features['subdomain_count'] = max(0, parsed.netloc.count('.') - 1)\n",
    "    features['contains_login'] = 1 if 'login' in url.lower() else 0\n",
    "    features['contains_verify'] = 1 if 'verify' in url.lower() else 0\n",
    "    features['contains_secure'] = 1 if 'secure' in url.lower() else 0\n",
    "    return features\n",
    "\n",
    "# Apply feature extraction\n",
    "phish_urls['url'] = phish_urls['url'].astype(str)\n",
    "feature_data = phish_urls['url'].apply(extract_features).apply(pd.Series)\n",
    "\n",
    "# Encode types: 0 ‚Üí benign, 1 ‚Üí phishing\n",
    "y_final = phish_urls['type'].apply(lambda x: 0 if x == 'benign' else 1).values\n",
    "X_numeric = feature_data\n",
    "\n",
    "# Get the EXACT list of feature names (no need for legacy alignment)\n",
    "numeric_feature_names = list(X_numeric.columns)\n",
    "\n",
    "# Save feature names for prediction time\n",
    "with open(\"numeric_feature_names.json\", \"w\") as f:\n",
    "    json.dump(numeric_feature_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7387e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 3Ô∏è‚É£ Scaling + TF-IDF\n",
    "# =======================\n",
    "\n",
    "# TF-IDF on URLs\n",
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(3, 5), max_features=3000)\n",
    "tfidf_features = vectorizer.fit_transform(phish_urls['url'])\n",
    "\n",
    "# Scaling on numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_numeric.fillna(0))\n",
    "\n",
    "# Final feature matrix (TF-IDF + Scaled Handcrafted Features)\n",
    "X_final = hstack([tfidf_features, X_scaled]).tocsr() # Convert to CSR for efficiency\n",
    "\n",
    "print(\"\\nDataset ready for training.\")\n",
    "print(f\"Final Feature Matrix Shape: {X_final.shape}\")\n",
    "\n",
    "# =======================\n",
    "# 4Ô∏è‚É£ Train-Test Split + Model Training\n",
    "# =======================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_final, y_final, test_size=0.2, random_state=42, stratify=y_final\n",
    ")\n",
    "\n",
    "# Calculate the imbalance factor (to improve precision)\n",
    "# ratio = Count(Benign) / Count(Phishing)\n",
    "ratio = len(y_final[y_final == 0]) / len(y_final[y_final == 1])\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'binary_logloss',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'n_estimators': 400,\n",
    "    'random_state': 42,\n",
    "    # Use a factor slightly higher than the ratio to heavily penalize False Positives\n",
    "    'scale_pos_weight': ratio * 1.5 \n",
    "}\n",
    "\n",
    "print(\"\\nüöÄ Training LightGBM model...\")\n",
    "lgb_model = lgb.LGBMClassifier(**params)\n",
    "lgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67484963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 5Ô∏è‚É£ Evaluation\n",
    "# =======================\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "y_prob = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nüìä Model Evaluation:\")\n",
    "print(f\"Accuracy  : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision : {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall    : {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 Score  : {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC   : {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Legitimate', 'Phishing'], yticklabels=['Legitimate', 'Phishing'])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "\n",
    "# =======================\n",
    "# 6Ô∏è‚É£ Save Model + Vectorizer + Scaler\n",
    "# =======================\n",
    "joblib.dump(lgb_model, \"phishing_lightgbm_model_simple.joblib\")\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer_simple.joblib\")\n",
    "joblib.dump(scaler, \"scaler_simple.joblib\")\n",
    "print(\"\\n‚úÖ Model, Vectorizer, and Scaler saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c61d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 7Ô∏è‚É£ Prediction Function\n",
    "# =======================\n",
    "with open(\"numeric_feature_names.json\", \"r\") as f:\n",
    "    numeric_feature_names = json.load(f)\n",
    "\n",
    "# Set a slightly stricter threshold to minimize False Positives\n",
    "PHISHING_THRESHOLD = 0.95 \n",
    "\n",
    "def predict_url(url):\n",
    "    \"\"\"Predicts the label for a single URL using the trained model and features.\"\"\"\n",
    "    \n",
    "    # 1. Extract Handcrafted Features\n",
    "    feats = extract_features(url)\n",
    "    feats_df = pd.DataFrame([feats])\n",
    "    \n",
    "    # 2. Align Features (Ensures the feature vector has the correct columns and order)\n",
    "    # This step is mainly for robustness against future changes, but essential for the scaler.\n",
    "    for col in numeric_feature_names:\n",
    "        if col not in feats_df.columns:\n",
    "            feats_df[col] = 0 \n",
    "    feats_df = feats_df[numeric_feature_names]\n",
    "    \n",
    "    # 3. Scale and Vectorize\n",
    "    feats_scaled = scaler.transform(feats_df.fillna(0))\n",
    "    tfidf_vec = vectorizer.transform([url]).tocsr() \n",
    "    \n",
    "    # 4. Combine and Predict\n",
    "    x = hstack([tfidf_vec, feats_scaled]).tocsr()\n",
    "    \n",
    "    # Use predict_proba to get the score\n",
    "    prob = lgb_model.predict_proba(x)[0, 1]\n",
    "    \n",
    "    # Apply the custom threshold\n",
    "    pred = 1 if prob >= PHISHING_THRESHOLD else 0\n",
    "    \n",
    "    print(f\"\\nüîó URL: {url}\")\n",
    "    print(f\"Prediction: {'Phishing' if pred == 1 else 'Legitimate'} (Probability: {prob:.4f}, Threshold: {PHISHING_THRESHOLD})\")\n",
    "    print(f\"Confidence: {prob:.2%}\")\n",
    "\n",
    "# =======================\n",
    "# 8Ô∏è‚É£ User Input Loop\n",
    "# =======================\n",
    "print(\"\\n--- Starting Interactive URL Checker ---\")\n",
    "while True:\n",
    "    user_url = input(\"\\n\\n---\\nEnter a URL to check (or type 'exit' to quit): \").strip()\n",
    "    if user_url.lower() == 'exit':\n",
    "        print(\"üëã Exiting URL checker.\")\n",
    "        break\n",
    "    if not user_url:\n",
    "        print(\"‚ö†Ô∏è Please enter a valid URL.\")\n",
    "        continue\n",
    "    try:\n",
    "        predict_url(user_url)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An error occurred during prediction: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
